import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
df = pd.read_csv('../Phase 3/Cleaned_Crime_Incidents.csv')
# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# Decision tree
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
dc = DecisionTreeClassifier()
dc_fit = dc.fit(X,y)
predictions = dc_fit.predict(X_test)
clf_report = classification_report(y_test, predictions, output_dict = True)
print(accuracy_score(y_test,predictions))
# code for visualization the outcome
clf_report

# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# Random Forest 
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
Rf = RandomForestClassifier()
Rf_fit = Rf.fit(X,y)
predictions = Rf_fit.predict(X_test)
clf_report = classification_report(y_test, predictions, output_dict = True)
print(accuracy_score(y_test,predictions))

# code for visualization the outcome
from sklearn.svm import SVC
clf = SVC(random_state=0,max_iter=1000)
clf.fit(X_train, y_train)
plot_confusion_matrix(clf, X_test, y_test) 
plt.show()

# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# AdaBoost Classifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score
ab = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=0.5, algorithm='SAMME.R', random_state=None)
ab.fit(X,y)
predictions = ab.predict(X_test)
accuracy_score(y_test,predictions)

# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# K Nearest Neighnour 
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
kc = KNeighborsClassifier()
kc_fit = kc.fit(X,y)
predictions = kc_fit.predict(X_test)
clf_report = classification_report(y_test, predictions, output_dict = True)
print(accuracy_score(y_test,predictions))

from sklearn.cluster import KMeans
import seaborn as sns

X = df.iloc[:, [0,7]].values

wcss = []
# Finding number of optimal clusters using the elbow method
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia)

# code for visualization the outcome
plt.figure(figsize=(10,5))
sns.lineplot(range(1, 11), wcss,marker='o',color='magenta')
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('Within Cluster Sum of Squares')
plt.show()


kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)
y_kmeans = kmeans.fit_predict(X)
print(accuracy_score(y_test,predictions))

# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# SVC
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
SVC = SVC()
SVC_fit = SVC.fit(X,y)
predictions = SVC_fit.predict(X_test)
clf_report = classification_report(y_test, predictions, output_dict = True)
print(accuracy_score(y_test,predictions))

# code for visualization the outcome
from sklearn.svm import SVC
clf = SVC(random_state=0,max_iter=1000)
clf.fit(X_train, y_train)
plot_confusion_matrix(clf, X_test, y_test) 
plt.show()

# code for modeling
X = df[['day_of_month', 'hour_of_day', 'day_of_week', 'neighborhood', 'council_district', 'police_district']]
y = df['parent_incident_type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)

# Logistic Regression 
from sklearn.linear_model import LogisticRegression 
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score
Lr = LogisticRegression()
Lr_fit = Lr.fit(X,y)
predictions = Lr_fit.predict(X_test)
clf_report = classification_report(y_test, predictions, output_dict = True)
print(accuracy_score(y_test,predictions))

# code for visualization the outcome
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(random_state=0,max_iter=1000)
clf.fit(X_train, y_train)
plot_confusion_matrix(clf, X_test, y_test) 
plt.show()






